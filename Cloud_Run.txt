
Cloud Run

https://cloud.google.com/run/docs/
Run stateless containers. Serverless. Triggered by web requests or PubSub events.
Cloud Run automatically scales your container up to handle the received requests, then scales down when demand decreases. You only pay for the CPU, Memory and Networking consumed during request handling
Whilst you won't be charged for when the service isn't running, you might still be charged for storing the container image in Container Registry - you can delete your image or your project to avoid charges

Reference: Differences between Cloud Run fully managed vs Cloud Run for Anthos
Note: the Anthos version is a GKE cluster with Cloud Run for Anthos
https://cloud.google.com/run/choosing-a-platform


-------------------------------------------------------------------------

# Test your Cloud Run is working
https://cloud.google.com/run/docs/quickstarts/prebuilt-deploy
Navigation > Cloud Run > Create Service
Container image: gcr.io/cloudrun/hello
Location: europe-west1
Service name: [your service name here]
Allow unauthenticased invocations

-------------------------------------------------------------------------

https://cloud.google.com/run/docs/quickstarts

------------------------------------------------------------------------------------------------------------

# How to Deploy a Container on Cloud Run
https://cloud.google.com/run/docs/quickstarts/build-and-deploy

# Initial setup
Enable Cloud Build & Cloud Run APIs
Install SDKs on local machine? https://cloud.google.com/sdk/docs/
Update components: gcloud components update

------------------------------------
app.py
------------------------------------
import os
from flask import Flask

app = Flask(__name__)

@app.route('/')
def hello_world():
    target = os.environ.get('TARGET', 'World')
    return 'Hello {}!\n'.format(target)

if __name__ == "__main__":
    app.run(debug=True,host='0.0.0.0',port=int(os.environ.get('PORT', 8080)))

------------------------------------
Dockerfile
------------------------------------
# Starts a Gunicorn web server that listens on the port defined by the PORT environment variable

# Use the official lightweight Python image.
# https://hub.docker.com/_/python
FROM python:3.7-slim

# Copy local code to the container image.
ENV APP_HOME /app
WORKDIR $APP_HOME
COPY . ./

# Install production dependencies.
RUN pip install Flask gunicorn

# Run the web service on container startup. Here we use the gunicorn
# webserver, with one worker process and 8 threads.
# For environments with multiple CPU cores, increase the number of workers
# to be equal to the cores available.
CMD exec gunicorn --bind :$PORT --workers 1 --threads 8 app:app

------------------------------------
# .dockerignore
------------------------------------
Dockerfile
README.md
*.pyc
*.pyo
*.pyd
__pycache__


# Build the container image using Cloud Build - stored in Container Registry
gcloud builds submit --tag gcr.io/PROJECT-ID/servicename

# Deploy the container
gcloud run deploy --image gcr.io/PROJECT-ID/servicename --platform managed
service name: servicename
region: europe-west1
allow unauthenticated invocation: y

# Delete an image from the Container Registry
https://cloud.google.com/sdk/gcloud/reference/container/images/delete
gcloud container images delete [HOSTNAME]/[PROJECT-ID]/[IMAGE]@[IMAGE_DIGEST]
gcloud container images delete [HOSTNAME]/[PROJECT-ID]/[IMAGE]:[TAG] --force-delete-tags
[HOSTNAME] is listed under Location in the console. It's one of four options: gcr.io, us.gcr.io, eu.gcr.io, or asia.gcr.io.
[PROJECT-ID] is your Google Cloud Console project ID. If your project ID has a colon in it (:) see Domain-scoped projects.
[IMAGE] is the image's name in Container Registry.
[IMAGE_DIGEST] is the sha256 hash value of the image contents.
[TAG] is the tag of the image you want to remove.


------------------------------------------------------------------------------------------------------------


------------------------------------
package.json
------------------------------------
{
  "name": "lab03",
  "version": "1.0.0",
  "description": "This is lab03 of the Pet Theory labs",
  "main": "index.js",
  "scripts": {
	"start": "node index.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [],
  "author": "Patrick - IT",
  "license": "MIT"
}


------------------------------------
index.js V1
------------------------------------
const express    = require('express');
const app        = express();
const bodyParser = require('body-parser');

app.use(bodyParser.json());

const port = process.env.PORT || 8080;

app.listen(port, () => {
  console.log('Listening on port', port);
});

app.post('/', async (req, res) => {
  console.log('OK');
  try {
    const file = decodeBase64Json(req.body.message.data);
    console.log(`file: ${JSON.stringify(file)}`);
  }
  catch (ex) {
    console.log(ex);
  }
  res.set('Content-Type', 'text/plain');
  res.send('\n\nOK\n\n');
})

function decodeBase64Json(data) {
  return JSON.parse(Buffer.from(data, 'base64').toString());
}

------------------------------------
index.js V2
------------------------------------
const {promisify} = require('util');
const {Storage}   = require('@google-cloud/storage');
const exec        = promisify(require('child_process').exec);
const storage     = new Storage();
const express    = require('express');
const app        = express();
const bodyParser = require('body-parser');

app.use(bodyParser.json());

const port = process.env.PORT || 8080;

app.listen(port, () => {
  console.log('Listening on port', port);
});

app.post('/', async (req, res) => {
  try {
    const file = decodeBase64Json(req.body.message.data);
    await downloadFile(file.bucket, file.name);
    const pdfFileName = await convertFile(file.name);
    await uploadFile(process.env.PDF_BUCKET, pdfFileName);
    await deleteFile(file.bucket, file.name);
  }
  catch (ex) {
    console.log(`Error: ${ex}`);
  }
  res.set('Content-Type', 'text/plain');
  res.send('\n\nOK\n\n');
})

function decodeBase64Json(data) {
  return JSON.parse(Buffer.from(data, 'base64').toString());
}

async function downloadFile(bucketName, fileName) {
  const options = {destination: `/tmp/${fileName}`};
  await storage.bucket(bucketName).file(fileName).download(options);
}

async function convertFile(fileName) {
  const cmd = 'libreoffice --headless --convert-to pdf --outdir /tmp ' +
              `"/tmp/${fileName}"`;
  console.log(cmd);
  const { stdout, stderr } = await exec(cmd);
  if (stderr) {
    throw stderr;
  }
  console.log(stdout);
  pdfFileName = fileName.replace(/\.\w+$/, '.pdf');
  return pdfFileName;
}

async function deleteFile(bucketName, fileName) {
  await storage.bucket(bucketName).file(fileName).delete();
}

async function uploadFile(bucketName, fileName) {
  await storage.bucket(bucketName).upload(`/tmp/${fileName}`);
}

------------------------------------
Dockerfile V1
------------------------------------
FROM node:12
WORKDIR /usr/src/app
COPY package.json package*.json ./
RUN npm install --only=production
COPY . .
CMD [ "npm", "start" ]

------------------------------------
Dockerfile V2
------------------------------------
FROM node:12
RUN apt-get update -y \
    && apt-get install -y libreoffice \
    && apt-get clean
WORKDIR /usr/src/app
COPY package.json package*.json ./
RUN npm install --only=production
COPY . .
CMD [ "npm", "start" ]


------------------------------------

# Place the above files into a folder and run shell from inside said folder

# Build
gcloud builds submit \
  --tag gcr.io/$GOOGLE_CLOUD_PROJECT/pdf-converter

# Deploy
gcloud beta run deploy pdf-converter \
  --image gcr.io/$GOOGLE_CLOUD_PROJECT/pdf-converter \
  --platform managed \
  --region us-central1 \
  --no-allow-unauthenticated

# Test - if return OK then it's working
SERVICE_URL=$(gcloud beta run services describe pdf-converter \
--platform managed --region us-central1 --format="value(status.url)")

curl -X POST -H "Authorization: Bearer $(gcloud auth print-identity-token)" $SERVICE_URL


# Make intermediary buckets
gsutil mb gs://$GOOGLE_CLOUD_PROJECT-upload
gsutil mb gs://$GOOGLE_CLOUD_PROJECT-processed

# Send a Pub/Sub notification whenever a new file has finished uploading to the docs bucket
gsutil notification create -t new-doc -f json -e OBJECT_FINALIZE gs://$GOOGLE_CLOUD_PROJECT-upload

# Create a new service account which Pub/Sub will use to trigger the Cloud Run services
gcloud iam service-accounts create pubsub-cloud-run-invoker --display-name "PubSub Cloud Run Invoker"

# Give the new service account permission to invoke the PDF converter service
gcloud beta run services add-iam-policy-binding pdf-converter --member=serviceAccount:pubsub-cloud-run-invoker@$GOOGLE_CLOUD_PROJECT.iam.gserviceaccount.com --role=roles/run.invoker --platform managed --region us-central1

# Get project number
gcloud projects list

# Set project number variable
PROJECT_NUMBER=577302394843

# Then enable your project to create Cloud Pub/Sub authentication tokens
gcloud projects add-iam-policy-binding $GOOGLE_CLOUD_PROJECT --member=serviceAccount:service-$PROJECT_NUMBER@gcp-sa-pubsub.iam.gserviceaccount.com --role=roles/iam.serviceAccountTokenCreator

# Create a Pub/Sub subscription so that the PDF converter can run whenever a message is published on the topic "new-doc"
gcloud beta pubsub subscriptions create pdf-conv-sub --topic new-doc --push-endpoint=$SERVICE_URL --push-auth-service-account=pubsub-cloud-run-invoker@$GOOGLE_CLOUD_PROJECT.iam.gserviceaccount.com



# Notes

const file = decodeBase64Json(req.body.message.data);
await downloadFile(file.bucket, file.name);
const pdfFileName = await convertFile(file.name);
await uploadFile(process.env.PDF_BUCKET, pdfFileName);
await deleteFile(file.bucket, file.name);
	
Whenever a file has been uploaded, this service gets triggered. It performs these tasks, one per line above:

Extracts the file details from the Pub/Sub notification.
Downloads the file from Cloud Storage to the local hard drive. This is actually not a physical disk, but a section of virtual memory that behaves like a disk.
Converts the downloaded file to PDF.
Uploads the PDF file to Cloud Storage. The environment variable process.env.PDF_BUCKET contains the name of the Cloud Storage bucket to write PDFs to. You will assign a value to this variable when you deploy the service below.
Deletes the original file from Cloud Storage.



# Build & deploy newer version

gcloud builds submit \
  --tag gcr.io/$GOOGLE_CLOUD_PROJECT/pdf-converter

gcloud beta run deploy pdf-converter \
  --image gcr.io/$GOOGLE_CLOUD_PROJECT/pdf-converter \
  --platform managed \
  --region us-central1 \
  --memory=2Gi \
  --no-allow-unauthenticated \
  --set-env-vars PDF_BUCKET=$GOOGLE_CLOUD_PROJECT-processed
  
  
  ------------------------------------------------------------------------------------------------------------


------------------------------------
app.py
------------------------------------
import os

from flask import Flask

app = Flask(__name__)

@app.route('/')
def hello_world():
    target = os.environ.get('TARGET', 'World')
    return 'Hello {}!\n'.format(target)
	
@app.route('/food')
def food():
    target = os.environ.get('TARGET', 'potatoes')
    return 'I love {}!\n'.format(target)

if __name__ == "__main__":
    app.run(debug=True,host='0.0.0.0',port=int(os.environ.get('PORT', 8080)))

------------------------------------
Dockerfile
------------------------------------
# Use the official lightweight Python image.
# https://hub.docker.com/_/python
FROM python:3.7-slim

# Copy local code to the container image.
ENV APP_HOME /app
WORKDIR $APP_HOME
COPY . ./

# Install production dependencies.
RUN pip install Flask gunicorn

# Run the web service on container startup. Here we use the gunicorn
# webserver, with one worker process and 8 threads.
# For environments with multiple CPU cores, increase the number of workers
# to be equal to the cores available.
CMD exec gunicorn --bind :$PORT --workers 1 --threads 8 app:app

------------------------------------
service.yml
------------------------------------
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: food
  namespace: default
spec:
  template:
    spec:
      containers:
      - image: docker.io/meiyongkpmg/food
        env:
        - name: TARGET
          value: "Python Sample v1"


# Build
gcloud builds submit \
  --tag gcr.io/$GOOGLE_CLOUD_PROJECT/foodtest

# Deploy
gcloud beta run deploy foodtest \
  --image gcr.io/$GOOGLE_CLOUD_PROJECT/foodtest \
  --platform managed \
  --region europe-west1 \
  --no-allow-unauthenticated

# Update the input variable
gcloud run services update foodtest \
--update-env-vars TARGET=carrots \
--platform managed \
--region europe-west1

# Trigger the food function in the app
curl -H "Authorization: Bearer $(gcloud auth print-identity-token)" https://foodtest-2mqxaowwiq-ew.a
.run.app/food












# Build
gcloud builds submit \
  --tag gcr.io/$GOOGLE_CLOUD_PROJECT/bqtest

# Deploy
gcloud beta run deploy bqtest \
  --image gcr.io/$GOOGLE_CLOUD_PROJECT/bqtest \
  --platform managed \
  --region europe-west1 \
  --no-allow-unauthenticated

# Trigger the bqtest function in the app
curl -H \
"Authorization: Bearer $(gcloud auth print-identity-token)" \
https://bqtest-2mqxaowwiq-ew.a.run.app/bqtest





